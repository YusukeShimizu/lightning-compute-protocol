---
title: openai-serve（OpenAI互換ゲートウェイ）
description: OpenAI互換のHTTPサーバ。lcpd-grpcd（Requester）へgRPCで転送します。
---

`openai-serve` は、OpenAI API の一部を実装する小さな HTTP ゲートウェイです。
受け取ったリクエストをローカルの `lcpd-grpcd`（Requester）へ gRPC で転送します。
Requester は Lightning 接続、見積もり（quote）/支払い、結果取得を担います。

これにより、既存の OpenAI 互換クライアント（SDK / LangChain / curl など）は、主に `base_url` を切り替えるだけで
LCP 上の Provider にリクエストを投げられます。

## アーキテクチャ

```text
OpenAI SDK / curl
   |
   |  HTTP（OpenAI互換）
   v
openai-serve
   |
   |  gRPC（LCPDService）
   v
lcpd-grpcd（Requester）  --- Lightning --- Provider peer（lcpd-grpcd Provider）
```

ポイント:

- `openai-serve` は意図的にステートレスで、Lightning へ直接接続しません。
- sats を支払う権限を持つのは Requester（`lcpd-grpcd`）です。

## 対応エンドポイント（MVP）

- `POST /v1/chat/completions`（非ストリーミングのみ）
- `GET /v1/models`
- `GET /healthz`

## クイックスタート

前提: `lcpd-grpcd` は別プロセスで起動（Requester モード）し、Lightning node と LCP peers に到達できる状態にします。

ビルド:

```sh
cd apps/openai-serve
go install ./cmd/openai-serve
```

起動:

```sh
export OPENAI_SERVE_HTTP_ADDR="127.0.0.1:8080"
export OPENAI_SERVE_LCPD_GRPC_ADDR="127.0.0.1:50051"

# 任意: 認証（カンマ区切り）
export OPENAI_SERVE_API_KEYS="devkey1"

openai-serve
```

動作確認:

```sh
curl -sS http://127.0.0.1:8080/v1/chat/completions \
  -H 'content-type: application/json' \
  -H 'authorization: Bearer devkey1' \
  -d '{
    "model": "gpt-5.2",
    "messages": [{"role":"user","content":"Say hello in Japanese."}]
  }'
```

## リクエスト/レスポンスの挙動

- JSON は strict に decode します（`DisallowUnknownFields`）: 未知フィールドがあると `400` になります。
- リクエストボディは 1 MiB までです。
- Provider の結果 bytes は UTF-8 必須です（UTF-8 でない場合は `502`）。
- レスポンスの token usage は概算です（bytes/4 の簡易ヒューリスティック）。

設定、ルーティング、Safety knobs（最大価格、タイムアウト、モデル allowlist）は
[設定](configuration-ja) を参照してください。

## LCP メタデータヘッダ

`POST /v1/chat/completions` のレスポンスには以下が含まれます:

- `X-Lcp-Peer-Id`: 選択された Provider の peer id
- `X-Lcp-Job-Id`: job id（hex）
- `X-Lcp-Price-Msat`: 受諾した quote の価格
- `X-Lcp-Terms-Hash`: 受諾した quote の terms hash（hex）

